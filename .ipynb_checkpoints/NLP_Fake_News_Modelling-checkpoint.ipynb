{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Assignment\n",
    "**Authors**: Vilhelm Stiernstedt & Sharon Mar√≠n Salazar\n",
    "<br>\n",
    "**Date**: 20/05/2018\n",
    "\n",
    "### Description\n",
    "Classification problem of News Report (document) for classes (FAKE, REAL). Try text-related classifiers such as Naive Bayes, MaxEnt, SVM. Use NLTK+SKLearn, NLP Pre-processing, Classifiers and CV-evaluation.\n",
    "\n",
    "#### Dataset\n",
    "**fake_or_real_news_training:**\n",
    "- ID: ID of the tweet\n",
    "- Title: Title of the news report\n",
    "- Text: Textual content of the news report\n",
    "- Label: Target Variable [FAKE, REAL]\n",
    "- X1, X2 additional fields\n",
    "\n",
    "**fake_or_real_news_test:**\n",
    "- ID, title and text\n",
    "- Predict Label\n",
    "\n",
    "#### Advices\n",
    "- Take a look to the data\n",
    "- Try the pre-processing methodologies we have seen in class\n",
    "- TF-IDF seems to be better (but try it!)\n",
    "- N-grams pay the effort\n",
    "- Less than 90-92%? -> Try again\n",
    "\n",
    "#### Plan\n",
    "1. Variable analysis\n",
    "    - Features\n",
    "    - Other insight\n",
    "2. Data Processing\n",
    "    - Drop features\n",
    "    - Label\n",
    "3. Modelling\n",
    "    - Navie Bayes\n",
    "    - SGD\n",
    "    - SVM\n",
    "        - linear\n",
    "        - rgb\n",
    "        - poly\n",
    "        - sigmod\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import MaxentClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import PipelineHelper # https://github.com/bmurauer/pipelinehelper/blob/master/pipelinehelper.py\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "\n",
    "# download required nltk packages (NB. commented out)\n",
    "# nltk.download()\n",
    "\n",
    "# plot settings\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas view settings -> see all contents of column\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Warning settings -> suppress depreciation warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build pipeline with multiple models\n",
    "# https://github.com/bmurauer/pipelinehelper/blob/master/pipelinehelper.py\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, ClassifierMixin\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "class PipelineHelper(BaseEstimator, TransformerMixin, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, available_models=None, selected_model=None, include_bypass=False):\n",
    "        self.include_bypass = include_bypass\n",
    "        self.selected_model = selected_model\n",
    "        # this is required for the clone operator used in gridsearch\n",
    "        if type(available_models) == dict:\n",
    "            self.available_models = available_models\n",
    "        # this is the case for constructing the helper initially\n",
    "        else:\n",
    "            # a string identifier is required for assigning parameters\n",
    "            self.available_models = {}\n",
    "            for (key, model) in available_models:\n",
    "                self.available_models[key] = model\n",
    "\n",
    "    def generate(self, param_dict={}):\n",
    "        per_model_parameters = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        # collect parameters for each specified model\n",
    "        for k, values in param_dict.items():\n",
    "            model_name = k.split('__')[0]\n",
    "            param_name = k[len(model_name)+2:]  # might be nested\n",
    "            if model_name not in self.available_models:\n",
    "                raise Exception('no such model: {0}'.format(model_name))\n",
    "            per_model_parameters[model_name][param_name] = values\n",
    "\n",
    "        ret = []\n",
    "\n",
    "        # create instance for cartesion product of all available parameters for each model\n",
    "        for model_name, param_dict in per_model_parameters.items():\n",
    "            parameter_sets = (dict(zip(param_dict, x)) for x in itertools.product(*param_dict.values()))\n",
    "            for parameters in parameter_sets:\n",
    "                ret.append((model_name, parameters))\n",
    "\n",
    "        # for every model that has no specified parameters, add the default model\n",
    "        for model_name in self.available_models.keys():\n",
    "            if model_name not in per_model_parameters:\n",
    "                ret.append((model_name, dict()))\n",
    "\n",
    "        # check if the stage is to be bypassed as one configuration\n",
    "        if self.include_bypass:\n",
    "            ret.append((None, dict(), True))\n",
    "        return ret\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'available_models': self.available_models,\n",
    "                'selected_model': self.selected_model,\n",
    "                'include_bypass': self.include_bypass}\n",
    "\n",
    "    def set_params(self, selected_model, available_models=None, include_bypass=False):\n",
    "        include_bypass = len(selected_model) == 3 and selected_model[2]\n",
    "\n",
    "        if available_models:\n",
    "            self.available_models = available_models\n",
    "\n",
    "        if selected_model[0] is None and include_bypass:\n",
    "            self.selected_model = None\n",
    "            self.include_bypass = True\n",
    "        else:\n",
    "            if selected_model[0] not in self.available_models:\n",
    "                raise Exception('so such model available: {0}'.format(selected_model[0]))\n",
    "            self.selected_model = self.available_models[selected_model[0]]\n",
    "            self.selected_model.set_params(**selected_model[1])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.selected_model is None and not self.include_bypass:\n",
    "            raise Exception('no model was set')\n",
    "        elif self.selected_model is None:\n",
    "            # print('bypassing model for fitting, returning self')\n",
    "            return self\n",
    "        else:\n",
    "            # print('using model for fitting: ', self.selected_model.__class__.__name__)\n",
    "            return self.selected_model.fit(X, y)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.selected_model is None and not self.include_bypass:\n",
    "            raise Exception('no model was set')\n",
    "        elif self.selected_model is None:\n",
    "            # print('bypassing model for transforming:')\n",
    "            # print(X[:10])\n",
    "            return X\n",
    "        else:\n",
    "            # print('using model for transforming: ', self.selected_model.__class__.__name__)\n",
    "            return self.selected_model.transform(X)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.include_bypass:\n",
    "            raise Exception('bypassing classifier is not allowed')\n",
    "        if self.selected_model is None:\n",
    "            raise Exception('no model was set')\n",
    "        return self.selected_model.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to data\n",
    "data_path = 'data/'\n",
    "\n",
    "# load test and train\n",
    "df_train = pd.read_csv(data_path+'training_clean.csv')\n",
    "df_test = pd.read_csv(data_path+'fake_or_real_news_test.csv')\n",
    "\n",
    "# set index\n",
    "df_train.set_index('ID', inplace=True)\n",
    "df_test.set_index('ID', inplace=True)\n",
    "\n",
    "# define combined df\n",
    "all_data = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing\n",
    "#### Stemmers & Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define count vectorizer for modelling (different parameter inputs will be given in modelling)\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# define Snowball stemmer (different parameter inputs will be given in modelling\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# define new vectorizer function with snowball stemmer\n",
    "class SnowballCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(SnowballCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([snowball_stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "# define new vectorizer function with Porter stemmer NLTK exten \n",
    "# (different parameter inputs will be given in modelling)\n",
    "porter_stemmer = PorterStemmer(mode='NLTK_EXTENSIONS')\n",
    "\n",
    "# define new vectorizer function with porter stemmer\n",
    "class PorterCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(PorterCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([porter_stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "# define lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# define new vectorizer function with stemmer\n",
    "class LemmatizerCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmatizerCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([lemmatizer.lemmatize(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline 1\n",
    "In our first pipeline we will try different type of vectorizer and stemmers with some parameter tuning. We hope that of these stemmers will be better than our baseline for all tested models. We will assess the following combinations:\n",
    "    - count vectorizer\n",
    "    - count vectorizer w. snowball stemmer\n",
    "    - count vectorizer w. porter stemmer\n",
    "    - count vectorizer w. lemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different feature subsets\n",
    "df_model = df_train.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label\n",
    "label = df_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data and labels into train and validation 80/20\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(df_model, label,\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline (vectorizer, models)\n",
    "pipeline = Pipeline([('vect', PipelineHelper([\n",
    "                            ('counter', CountVectorizer()),\n",
    "                            ('snowball_stemmer', SnowballCountVectorizer()),\n",
    "                            ('porter_stemmer', PorterCountVectorizer()),\n",
    "                            ('lemmatizer', LemmatizerCountVectorizer()),\n",
    "                        ])),\n",
    "                     ('clf', PipelineHelper([\n",
    "                            #('sgd', SGDClassifier(n_iter=1000)),\n",
    "                            #('svm-lin', LinearSVC()),\n",
    "                            #('svm-ker', SVC()),\n",
    "                            #('multi_nb', MultinomialNB()),\n",
    "                        ])),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "We will extend the model parameters and hope to imporve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipline parameters\n",
    "parameters = {'vect__selected_model': pipeline.named_steps['vect'].generate({\n",
    "                  'counter__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
    "                  'counter__stop_words': ('english', None),\n",
    "                  'counter__lowercase': (True, False),\n",
    "                  'snowball_stemmer__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
    "                  'snowball_stemmer__stop_words': ('english', None),\n",
    "                  'snowball_stemmer__lowercase': (True, False),\n",
    "                  'porter_stemmer__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
    "                  'porter_stemmer__stop_words': ('english', None),\n",
    "                  'porter_stemmer__lowercase': (True, False),\n",
    "                  'lemmatizer__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
    "                  'lemmatizer__stop_words': ('english', None),\n",
    "                  'lemmatizer__lowercase': (True, False),\n",
    "                }),\n",
    "              'clf__selected_model': pipeline.named_steps['clf'].generate({\n",
    "                #  'sgd__alpha': (1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3),\n",
    "                #  'sgd__loss': ('hinge', 'squared_hinge', 'log'),\n",
    "                #  'sgd__l1_ratio': (0, 0.1, 0.25, 0.5, 0.75, 1.0),\n",
    "                #  'svm-lin__penalty': ('l1', 'l2'),\n",
    "                #  'svm-lin__loss': ('hinge', 'squared_hinge'),\n",
    "                #  'svm-lin__C': (0.1, 1, 10, 50, 100, 500, 1000),\n",
    "                  'svm-ker__kernel': ('rbf', 'poly', 'sigmoid'),\n",
    "                  'svm-ker__C': (0.1, 1, 10, 50, 100, 500, 1000),\n",
    "                  #'multi_nb__alpha': (0.1, 0.25, 0.5, 0.75, 1)\n",
    "                })\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}) \n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}) \n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}), score=0.7638238050609185, total= 9.2min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}), score=0.7589118198874296, total= 9.3min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000000.0}), score=0.8123827392120075, total= 9.3min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}), score=0.7544517338331771, total= 3.6min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}), score=0.7298311444652908, total= 3.6min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 10000000000.0}), score=0.7270168855534709, total= 3.7min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}), score=0.7760074976569822, total= 5.5min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}), score=0.7476547842401501, total= 5.5min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 100.0}), score=0.7392120075046904, total= 5.6min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8697282099343955, total=12.1min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8639774859287055, total=12.1min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8658536585365854, total=12.2min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}), score=0.8331771321462043, total= 6.7min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}), score=0.8311444652908068, total= 6.8min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000.0}), score=0.8545966228893058, total= 6.8min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7582005623242737, total= 5.5min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7401500938086304, total= 5.6min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7326454033771107, total= 5.5min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8678537956888472, total= 1.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed: 61.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8789868667917449, total= 1.3min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000.0}), score=0.8818011257035647, total= 1.3min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8612933458294283, total= 3.4min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8714821763602252, total= 3.4min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8621013133208255, total= 3.5min\n",
      "[CV] vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}), score=0.8903467666354264, total=12.4min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}), score=0.8958724202626641, total=12.4min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('porter_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000.0}), score=0.8958724202626641, total=12.4min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}), score=0.8069353327085286, total= 1.7min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}), score=0.7954971857410882, total= 1.8min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100.0}), score=0.7898686679174484, total= 1.8min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}), score=0.5023430178069354, total= 2.1min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}), score=0.50093808630394, total= 2.1min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000.0}), score=0.5028142589118199, total= 2.2min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7319587628865979, total= 1.6min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7101313320825516, total= 1.6min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7073170731707317, total= 1.6min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}), score=0.5023430178069354, total= 1.2min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}), score=0.5028142589118199, total= 1.3min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 4), 'stop_words': 'english', 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 0.1}), score=0.5028142589118199, total= 1.3min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8622305529522024, total=61.0min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8602251407129456, total=61.4min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 100000.0}), score=0.8639774859287055, total=61.2min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}), score=0.7966260543580131, total=132.1min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}), score=0.9015009380863039, total=132.3min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 10000.0}), score=0.8123827392120075, total=141.4min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}), score=0.837863167760075, total=41.1min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}), score=0.5023430178069354, total=19.7min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}), score=0.8564727954971857, total=50.5min\n",
      "[CV] vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 1000000000.0}), score=0.851782363977486, total=50.5min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}), score=0.5028142589118199, total=19.8min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}) \n",
      "[CV]  vect__selected_model=('counter', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'sigmoid', 'C': 1.0}), score=0.5028142589118199, total=10.5min\n",
      "[CV] vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}), score=0.837863167760075, total=50.8min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}), score=0.8564727954971857, total=50.7min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('lemmatizer', {'ngram_range': (1, 4), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'rbf', 'C': 10000000.0}), score=0.851782363977486, total=51.0min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7582005623242737, total=11.2min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7420262664165104, total= 3.9min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 2), 'stop_words': None, 'lowercase': False}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000.0}), score=0.7317073170731707, total= 3.9min\n",
      "[CV] vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}) \n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}), score=0.6785379568884724, total= 3.7min\n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}), score=0.6407129455909943, total= 3.8min\n",
      "[CV]  vect__selected_model=('snowball_stemmer', {'ngram_range': (1, 3), 'stop_words': 'english', 'lowercase': True}), clf__selected_model=('svm-ker', {'kernel': 'poly', 'C': 1000000000.0}), score=0.6378986866791745, total= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed: 568.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8940293841825571"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define random search grid with cv\n",
    "rscv_clf = RandomizedSearchCV(estimator=pipeline, verbose=4,\n",
    "                              param_distributions=parameters,\n",
    "                              n_jobs=3, n_iter=20, cv=3, \n",
    "                              random_state=42)\n",
    "\n",
    "# fit model based\n",
    "rscv_clf_mod = rscv_clf.fit(x_train, y_train)\n",
    "\n",
    "# get best score from CV\n",
    "rscv_clf_mod.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__selected_model': ('svm-ker', {'C': 10000.0, 'kernel': 'rbf'}),\n",
       " 'vect__selected_model': ('porter_stemmer',\n",
       "  {'lowercase': True, 'ngram_range': (1, 4), 'stop_words': None})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters for best score from CV\n",
    "rscv_clf_mod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.86      0.94      0.90       383\n",
      "       REAL       0.94      0.86      0.90       417\n",
      "\n",
      "avg / total       0.90      0.90      0.90       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "rscv_clf_pred = rscv_clf_mod.best_estimator_.predict(x_validation)\n",
    "\n",
    "# model evaluation\n",
    "print(metrics.classification_report(y_validation, rscv_clf_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[360  23]\n",
      " [ 59 358]]\n",
      "Normalized confusion matrix\n",
      "[[0.94 0.06]\n",
      " [0.14 0.86]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_validation, rscv_clf_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=label,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=label, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Pipeline 2\n",
    "Our second pipeline will introduce an tf-idf to see if some of our models improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for orginal text\n",
    "df_model = df_train['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label\n",
    "label = df_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data and labels into train and validation 80/20\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(df_model, label,\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline (vectorizer, models)\n",
    "pipeline = Pipeline([('vect', PipelineHelper([\n",
    "                            ('counter', CountVectorizer()),\n",
    "                            ('snowball_stemmer', SnowballCountVectorizer()),\n",
    "                            ('porter_stemmer', PorterCountVectorizer()),\n",
    "                            ('lemmatizer', LemmatizerCountVectorizer()),\n",
    "                        ])),\n",
    "                     ('tf-idf', TfidfTransformer()),\n",
    "                     ('clf', PipelineHelper([\n",
    "                            ('svm', SGDClassifier()),\n",
    "                            ('multi_nb', MultinomialNB()),\n",
    "                        ])),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters\n",
    "We will extend the model parameters and hope to imporve our score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipline parameters\n",
    "parameters = {'vect__selected_model': pipeline.named_steps['vect'].generate({\n",
    "                  'counter__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'counter__stop_words': ('english', None),\n",
    "                  'counter__lowercase': (True, False),\n",
    "                  'snowball_stemmer__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'snowball_stemmer__stop_words': ('english', None),\n",
    "                  'snowball_stemmer__lowercase': (True, False),\n",
    "                  'porter_stemmer__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'porter_stemmer__stop_words': ('english', None),\n",
    "                  'porter_stemmer__lowercase': (True, False),\n",
    "                  'lemmatizer__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'lemmatizer__stop_words': ('english', None),\n",
    "                  'lemmatizer__lowercase': (True, False),\n",
    "                }),\n",
    "              'tf-idf__use_idf': (True, False),\n",
    "              'clf__selected_model': pipeline.named_steps['clf'].generate({\n",
    "                  'svm__alpha': (0.5, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6),\n",
    "                  'svm__loss': ('hinge', 'squared_hinge'),\n",
    "                  'svm__l1_ratio': (0, 0.1, 0.25, 0.5, 0.75, 1.0),\n",
    "                  'multi_nb__alpha': (0.1, 0.25, 0.5, 0.75, 1)\n",
    "                })\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   31.2s\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "[Parallel(n_jobs=3)]: Done  90 out of  90 | elapsed:   55.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8227571115973742"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define random search grid with cv\n",
    "rscv_clf = RandomizedSearchCV(estimator=pipeline, verbose=1,\n",
    "                              param_distributions=parameters,\n",
    "                              n_jobs=3, n_iter=30, cv=3, \n",
    "                              random_state=42)\n",
    "\n",
    "# fit model based\n",
    "rscv_clf_mod = rscv_clf.fit(x_train, y_train)\n",
    "\n",
    "# get best score from CV\n",
    "rscv_clf_mod.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__selected_model': ('svm',\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.25, 'loss': 'hinge'}),\n",
       " 'vect__selected_model': ('lemmatizer',\n",
       "  {'lowercase': True, 'ngram_range': (1, 2), 'stop_words': 'english'})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get parameters for best score from CV\n",
    "rscv_clf_mod.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.89      0.92      0.90       383\n",
      "       REAL       0.93      0.89      0.91       417\n",
      "\n",
      "avg / total       0.91      0.91      0.91       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "rscv_clf_pred = rscv_clf_mod.best_estimator_.predict(x_validation)\n",
    "\n",
    "# model evaluation\n",
    "print(metrics.classification_report(y_validation, rscv_clf_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
