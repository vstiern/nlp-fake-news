{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Assignment\n",
    "**Authors**: Vilhelm Stiernstedt & Sharon Mar√≠n Salazar\n",
    "<br>\n",
    "**Date**: 20/05/2018\n",
    "\n",
    "### Description\n",
    "Classification problem of News Report (document) for classes (FAKE, REAL). Try text-related classifiers such as Naive Bayes, MaxEnt, SVM. Use NLTK+SKLearn, NLP Pre-processing, Classifiers and CV-evaluation.\n",
    "\n",
    "#### Dataset\n",
    "**fake_or_real_news_training:**\n",
    "- ID: ID of the tweet\n",
    "- Title: Title of the news report\n",
    "- Text: Textual content of the news report\n",
    "- Label: Target Variable [FAKE, REAL]\n",
    "- X1, X2 additional fields\n",
    "\n",
    "**fake_or_real_news_test:**\n",
    "- ID, title and text\n",
    "- Predict Label\n",
    "\n",
    "#### Advices\n",
    "- Take a look to the data\n",
    "- Try the pre-processing methodologies we have seen in class\n",
    "- TF-IDF seems to be better (but try it!)\n",
    "- N-grams pay the effort\n",
    "- Less than 90-92%? -> Try again\n",
    "\n",
    "#### Plan\n",
    "1. Variable analysis\n",
    "    - Features\n",
    "    - Other insight\n",
    "2. Data Processing\n",
    "    - Drop features\n",
    "    - Label\n",
    "3. Modelling\n",
    "    - Navie Bayes\n",
    "    - MaxEnt\n",
    "    - SVM\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import MaxentClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import PipelineHelper # https://github.com/bmurauer/pipelinehelper/blob/master/pipelinehelper.py\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "\n",
    "# download required nltk packages (NB. commented out)\n",
    "# nltk.download()\n",
    "\n",
    "# plot settings\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas view settings -> see all contents of column\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Warning settings -> suppress depreciation warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions\n",
    "### Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stop words - english\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# define lemmatizer for simple analysis \n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# create normalization function for analysis of title and text\n",
    "def normalizer(text):\n",
    "    clean_text = re.sub('[^\\x00-\\x7F]+', \"\", text) # remove non-ascii characters\n",
    "    clean_text = re.sub('(\\r)+', \"\",  clean_text) # remove newline characters\n",
    "    clean_text = re.sub(r'@([A-Za-z0-9_]+)', \"\",  clean_text) # remove twitter handles\n",
    "    clean_text = re.sub(r\"(https|http)\\S+\", \"\",  clean_text) # remove hyperlinks\n",
    "    clean_text = re.sub(\"[^a-zA-Z]\", \" \", clean_text) # remove all but letters remains\n",
    "    tokens = nltk.word_tokenize(clean_text)[2:] # tokenize words\n",
    "    lower_case = [l.lower() for l in tokens] # convert to lowercase\n",
    "    filtered_result = list(filter(lambda l: l not in stop_words, lower_case)) # filter stopwords\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result] # stem words with lemmatizer\n",
    "    return lemmas\n",
    "\n",
    "# define function to construct our ngrams for analysis of title and text\n",
    "def ngrams(input_list):\n",
    "    bigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:]))]\n",
    "    trigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[2:]))]\n",
    "    quadgrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[3:]))]\n",
    "    return bigrams+trigrams+quadgrams\n",
    "\n",
    "# define function to count words for analysis of ngrams (bi, tri, quad) for title and text\n",
    "def count_words(input):\n",
    "    cnt = collections.Counter()\n",
    "    for row in input:\n",
    "        for word in row:\n",
    "            cnt[word] += 1\n",
    "    return cnt\n",
    "\n",
    "# exclaimation counter for analysis of text (potentially introduce as new feautre)\n",
    "def exclaimation_counter(article):\n",
    "    nr_abs = article.count('!')\n",
    "    text_len = len(article)\n",
    "    nr_rel = nr_abs/text_len\n",
    "    return nr_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing\n",
    "#### Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define count vectorizer for modelling (different parameter inputs will be given in modelling)\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# define Snowball stemmer (different parameter inputs will be given in modelling\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# define new vectorizer function with snowball stemmer\n",
    "class SnowballCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(SnowballCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([snowball_stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "# define new vectorizer function with Porter stemmer NLTK exten \n",
    "# (different parameter inputs will be given in modelling)\n",
    "porter_stemmer = PorterStemmer(mode='NLTK_EXTENSIONS')\n",
    "\n",
    "# define new vectorizer function with porter stemmer\n",
    "class PorterCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(PorterCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([porter_stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build pipeline with multiple models\n",
    "# https://github.com/bmurauer/pipelinehelper/blob/master/pipelinehelper.py\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, ClassifierMixin\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "class PipelineHelper(BaseEstimator, TransformerMixin, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, available_models=None, selected_model=None, include_bypass=False):\n",
    "        self.include_bypass = include_bypass\n",
    "        self.selected_model = selected_model\n",
    "        # this is required for the clone operator used in gridsearch\n",
    "        if type(available_models) == dict:\n",
    "            self.available_models = available_models\n",
    "        # this is the case for constructing the helper initially\n",
    "        else:\n",
    "            # a string identifier is required for assigning parameters\n",
    "            self.available_models = {}\n",
    "            for (key, model) in available_models:\n",
    "                self.available_models[key] = model\n",
    "\n",
    "    def generate(self, param_dict={}):\n",
    "        per_model_parameters = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        # collect parameters for each specified model\n",
    "        for k, values in param_dict.items():\n",
    "            model_name = k.split('__')[0]\n",
    "            param_name = k[len(model_name)+2:]  # might be nested\n",
    "            if model_name not in self.available_models:\n",
    "                raise Exception('no such model: {0}'.format(model_name))\n",
    "            per_model_parameters[model_name][param_name] = values\n",
    "\n",
    "        ret = []\n",
    "\n",
    "        # create instance for cartesion product of all available parameters for each model\n",
    "        for model_name, param_dict in per_model_parameters.items():\n",
    "            parameter_sets = (dict(zip(param_dict, x)) for x in itertools.product(*param_dict.values()))\n",
    "            for parameters in parameter_sets:\n",
    "                ret.append((model_name, parameters))\n",
    "\n",
    "        # for every model that has no specified parameters, add the default model\n",
    "        for model_name in self.available_models.keys():\n",
    "            if model_name not in per_model_parameters:\n",
    "                ret.append((model_name, dict()))\n",
    "\n",
    "        # check if the stage is to be bypassed as one configuration\n",
    "        if self.include_bypass:\n",
    "            ret.append((None, dict(), True))\n",
    "        return ret\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'available_models': self.available_models,\n",
    "                'selected_model': self.selected_model,\n",
    "                'include_bypass': self.include_bypass}\n",
    "\n",
    "    def set_params(self, selected_model, available_models=None, include_bypass=False):\n",
    "        include_bypass = len(selected_model) == 3 and selected_model[2]\n",
    "\n",
    "        if available_models:\n",
    "            self.available_models = available_models\n",
    "\n",
    "        if selected_model[0] is None and include_bypass:\n",
    "            self.selected_model = None\n",
    "            self.include_bypass = True\n",
    "        else:\n",
    "            if selected_model[0] not in self.available_models:\n",
    "                raise Exception('so such model available: {0}'.format(selected_model[0]))\n",
    "            self.selected_model = self.available_models[selected_model[0]]\n",
    "            self.selected_model.set_params(**selected_model[1])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.selected_model is None and not self.include_bypass:\n",
    "            raise Exception('no model was set')\n",
    "        elif self.selected_model is None:\n",
    "            # print('bypassing model for fitting, returning self')\n",
    "            return self\n",
    "        else:\n",
    "            # print('using model for fitting: ', self.selected_model.__class__.__name__)\n",
    "            return self.selected_model.fit(X, y)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.selected_model is None and not self.include_bypass:\n",
    "            raise Exception('no model was set')\n",
    "        elif self.selected_model is None:\n",
    "            # print('bypassing model for transforming:')\n",
    "            # print(X[:10])\n",
    "            return X\n",
    "        else:\n",
    "            # print('using model for transforming: ', self.selected_model.__class__.__name__)\n",
    "            return self.selected_model.transform(X)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.include_bypass:\n",
    "            raise Exception('bypassing classifier is not allowed')\n",
    "        if self.selected_model is None:\n",
    "            raise Exception('no model was set')\n",
    "        return self.selected_model.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to data\n",
    "data_path = 'data/'\n",
    "\n",
    "# load test and train\n",
    "df_train = pd.read_csv(data_path+'fake_or_real_news_training.csv')\n",
    "df_test = pd.read_csv(data_path+'fake_or_real_news_test.csv')\n",
    "\n",
    "# set index\n",
    "df_train.set_index('ID', inplace=True)\n",
    "df_test.set_index('ID', inplace=True)\n",
    "\n",
    "# define combined df\n",
    "all_data = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimension of training data\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2321, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimension of test data -> more than one column difference!\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3999 entries, 8476 to 9673\n",
      "Data columns (total 5 columns):\n",
      "title    3999 non-null object\n",
      "text     3999 non-null object\n",
      "label    3999 non-null object\n",
      "X1       33 non-null object\n",
      "X2       2 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 187.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# check column names and dtypes for training data\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2321 entries, 10498 to 4330\n",
      "Data columns (total 2 columns):\n",
      "title    2321 non-null object\n",
      "text     2321 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 54.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# check column names and dtypes for test data\n",
    "# -> X1 and X2 not in testset ... -> need manipulation to be used for modelling\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check df_train -> text lengthy ...\n",
    "# df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>September New Homes Sales Rise‚Äî‚Äî-Back To 1992 Level!</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Level! By David Stockman. Posted On Wednesday, October 26th, 2016 \\n\\nDavid Stockman's Contra Corner is the only place where mainstream delusions and cant about the Warfare State, the Bailout State, Bubble Finance and Beltway Banditry are ripped, refuted and rebuked. Subscribe now to receive David Stockman‚Äôs latest posts by email each day as well as his model portfolio, Lee Adler‚Äôs Daily Data Dive and David‚Äôs personally curated insights and analysis from leading contrarian thinkers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title  \\\n",
       "ID                                                            \n",
       "10498  September New Homes Sales Rise‚Äî‚Äî-Back To 1992 Level!   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "10498  September New Homes Sales Rise Back To 1992 Level! By David Stockman. Posted On Wednesday, October 26th, 2016 \\n\\nDavid Stockman's Contra Corner is the only place where mainstream delusions and cant about the Warfare State, the Bailout State, Bubble Finance and Beltway Banditry are ripped, refuted and rebuked. Subscribe now to receive David Stockman‚Äôs latest posts by email each day as well as his model portfolio, Lee Adler‚Äôs Daily Data Dive and David‚Äôs personally curated insights and analysis from leading contrarian thinkers.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check df_test -> similar structure as train -> good.\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0   \n",
       "text     0   \n",
       "label    0   \n",
       "X1       3966\n",
       "X2       3997\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values for training data -> X1 and X2 almost 100% NaNs -> probably drop values\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values for training data -> all unnamed almost 100% NaNs, tweet_coord 90%\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     33  \n",
       "unique    4   \n",
       "top       REAL\n",
       "freq      17  \n",
       "Name: X1, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general overview -> mostly unique titles, 4 identical could suggest duplictes exist. \n",
    "df_train.X1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view rows where X1 != NaN\n",
    "# value counts -> seems that variable include data that has miss aligned\n",
    "# lets look at independet rows and see the values belong to other column\n",
    "# either title is long been splitted into both fields (title and text) and thus shifted everything else rightwards\n",
    "# df_train[df_train.X1.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title merge test -> works!\n",
    "# df_train.loc[599]['title'] + '' + df_train.loc[599]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build function to shift all row fields left where X1 != NaN\n",
    "for id in df_train[df_train.X1.notnull()].index:\n",
    "    # title will be a concatenation of title and text\n",
    "    df_train.loc[id]['title'] = df_train.loc[id]['title'] + '' + df_train.loc[id]['text']\n",
    "    # text will be current label\n",
    "    df_train.loc[id]['text'] = df_train.loc[id]['label']\n",
    "    # label will be current X1\n",
    "    df_train.loc[id]['label'] = df_train.loc[id]['X1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview X1 again -> looks good\n",
    "# df_train[df_train.X1.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  notes\n",
    "At this stage X1 doesn't contain any useful data, we can remove it completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2   \n",
       "unique    2   \n",
       "top       FAKE\n",
       "freq      1   \n",
       "Name: X2, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general overview -> mostly unique titles, 4 identical could suggest duplictes exist. \n",
    "df_train.X2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view rows where X2 != NaN\n",
    "# seems that variable include data that has miss aligned just like X1\n",
    "# from our last shift, we only need to merge title and text, move label to text, and X2 to label\n",
    "# df_train[df_train.X2.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build function to shift all row fields left where X2 != NaN\n",
    "for id in df_train[df_train.X2.notnull()].index:\n",
    "    # title will be a concatenation of title and text\n",
    "    df_train.loc[id]['title'] = df_train.loc[id]['title'] + '' + df_train.loc[id]['text']\n",
    "    # text will be current label\n",
    "    df_train.loc[id]['text'] = df_train.loc[id]['label']\n",
    "    # label will be current X2\n",
    "    df_train.loc[id]['label'] = df_train.loc[id]['X2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview X2 again -> looks good\n",
    "# df_train[df_train.X2.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  notes\n",
    "At this stage X2 doesn't contain any useful data, we can remove it completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    2008\n",
       "FAKE    1991\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most important is that labels are corrct -> yes, only fake and real!\n",
    "# also almost equal split of fake and real articles\n",
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3999                         \n",
       "unique    3968                         \n",
       "top       OnPolitics | 's politics blog\n",
       "freq      4                            \n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general overview -> mostly unique titles, 4 identical could suggest duplictes exist. \n",
    "df_train.title.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wordcloud - Fake news\n",
    "Most common word used in fake news titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for negative sentiment\n",
    "df_cloud = df_train[df_train['label']=='FAKE']\n",
    "\n",
    "# subset all words in text based on space\n",
    "words = ' '.join(df_cloud['title'])\n",
    "\n",
    "# split words\n",
    "split_words = \" \".join([word for word in words.split()])\n",
    "\n",
    "# create wordcloud based on word frequancy\n",
    "# wordcloud = WordCloud(stopwords=STOPWORDS, # remove stopwords\n",
    "                      background_color='white',\n",
    "                      width=3000,\n",
    "                      height=2500\n",
    "                     ).generate(split_words)\n",
    "\n",
    "# plot wordcloud\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wordcloud - Real news\n",
    "Most common word used in real news titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for negative sentiment\n",
    "df_cloud = df_train[df_train['label']=='REAL']\n",
    "\n",
    "# subset all words in text based on space\n",
    "words = ' '.join(df_cloud['title'])\n",
    "\n",
    "# split words\n",
    "split_words = \" \".join([word for word in words.split()])\n",
    "\n",
    "# create wordcloud based on word frequancy\n",
    "# wordcloud = WordCloud(stopwords=STOPWORDS, # remove stopwords\n",
    "                      background_color='white',\n",
    "                      width=3000,\n",
    "                      height=2500\n",
    "                     ).generate(split_words)\n",
    "\n",
    "# plot wordcloud\n",
    "plt.figure(1, figsize=(10, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize text\n",
    "Lets try to structure the titles and remove all unuseful elements to conduct a better analysis. Such as:\n",
    "- Remove all but letters\n",
    "- Tokenize words\n",
    "- Convert to lowercase\n",
    "- Filter stopwords\n",
    "- Stem words with lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_normalized</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary‚Äôs Fear</td>\n",
       "      <td>[smell, hillary, fear]</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Political Suicide At A Trump Rally (VIDEO)</td>\n",
       "      <td>[exact, moment, paul, ryan, committed, political, suicide, trump, rally, video]</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>[go, paris, gesture, sympathy]</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger against the DNC: 'We tried to warn you!'</td>\n",
       "      <td>[twitter, erupt, anger, dnc, tried, warn]</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>[new, york, primary, matter]</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       title  \\\n",
       "ID                                                                                             \n",
       "8476   You Can Smell Hillary‚Äôs Fear                                                            \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Political Suicide At A Trump Rally (VIDEO)   \n",
       "3608   Kerry to go to Paris in gesture of sympathy                                             \n",
       "10142  Bernie supporters on Twitter erupt in anger against the DNC: 'We tried to warn you!'    \n",
       "875    The Battle of New York: Why This Primary Matters                                        \n",
       "\n",
       "                                                                      title_normalized  \\\n",
       "ID                                                                                       \n",
       "8476   [smell, hillary, fear]                                                            \n",
       "10294  [exact, moment, paul, ryan, committed, political, suicide, trump, rally, video]   \n",
       "3608   [go, paris, gesture, sympathy]                                                    \n",
       "10142  [twitter, erupt, anger, dnc, tried, warn]                                         \n",
       "875    [new, york, primary, matter]                                                      \n",
       "\n",
       "      label  \n",
       "ID           \n",
       "8476   FAKE  \n",
       "10294  FAKE  \n",
       "3608   REAL  \n",
       "10142  FAKE  \n",
       "875    REAL  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new feature -> apply function on text\n",
    "df_train['title_normalized'] = df_train.title.apply(normalizer)\n",
    "\n",
    "# view reuslts -> some desired words seem to fall off, perhaps lammatizer not best tool for stemming.\n",
    "# We will try other methods for our modelling such as snowball and porter stemmers.\n",
    "df_train[['title','title_normalized', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngrams\n",
    "As words mostly matter in context we'll look at bi, tri, quad-grams instead of just individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_grams</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>[smell hillary, hillary fear, smell hillary fear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>[exact moment, moment paul, paul ryan, ryan committed, committed political, political suicide, suicide trump, trump rally, rally video, exact moment paul, moment paul ryan, paul ryan committed, ryan committed political, committed political suicide, political suicide trump, suicide trump rally, trump rally video, exact moment ryan, moment paul committed, paul ryan political, ryan committed suicide, committed political trump, political suicide rally, suicide trump video]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>[go paris, paris gesture, gesture sympathy, go paris gesture, paris gesture sympathy, go paris sympathy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>[twitter erupt, erupt anger, anger dnc, dnc tried, tried warn, twitter erupt anger, erupt anger dnc, anger dnc tried, dnc tried warn, twitter erupt dnc, erupt anger tried, anger dnc warn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>[new york, york primary, primary matter, new york primary, york primary matter, new york matter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     title_grams\n",
       "ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "8476   [smell hillary, hillary fear, smell hillary fear]                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "10294  [exact moment, moment paul, paul ryan, ryan committed, committed political, political suicide, suicide trump, trump rally, rally video, exact moment paul, moment paul ryan, paul ryan committed, ryan committed political, committed political suicide, political suicide trump, suicide trump rally, trump rally video, exact moment ryan, moment paul committed, paul ryan political, ryan committed suicide, committed political trump, political suicide rally, suicide trump video]\n",
       "3608   [go paris, paris gesture, gesture sympathy, go paris gesture, paris gesture sympathy, go paris sympathy]                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "10142  [twitter erupt, erupt anger, anger dnc, dnc tried, tried warn, twitter erupt anger, erupt anger dnc, anger dnc tried, dnc tried warn, twitter erupt dnc, erupt anger tried, anger dnc warn]                                                                                                                                                                                                                                                                                              \n",
       "875    [new york, york primary, primary matter, new york primary, york primary matter, new york matter]                                                                                                                                                                                                                                                                                                                                                                                         "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new feature -> apply function on normalized_text\n",
    "df_train['title_grams'] = df_train.title_normalized.apply(ngrams)\n",
    "\n",
    "# view reuslts\n",
    "df_train[['title_grams']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency count - Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hillary clinton', 51),\n",
       " ('donald trump', 32),\n",
       " ('onion america', 23),\n",
       " ('america finest', 23),\n",
       " ('finest news', 23),\n",
       " ('news source', 23),\n",
       " ('onion america finest', 23),\n",
       " ('america finest news', 23),\n",
       " ('finest news source', 23),\n",
       " ('onion america news', 23),\n",
       " ('america finest source', 23),\n",
       " ('clinton email', 18),\n",
       " ('world war', 13),\n",
       " ('email investigation', 12),\n",
       " ('clinton foundation', 12),\n",
       " ('standing rock', 11),\n",
       " ('u election', 11),\n",
       " ('hillary campaign', 9),\n",
       " ('fbi director', 8),\n",
       " ('trump supporter', 8)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show 20 most common words form ngrams for fake news\n",
    "df_train[(df_train.label == 'FAKE')][['title_grams']].apply(count_words)['title_grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency count - Real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald trump', 55),\n",
       " ('hillary clinton', 36),\n",
       " ('white house', 22),\n",
       " ('supreme court', 17),\n",
       " ('bernie sander', 14),\n",
       " ('gop debate', 14),\n",
       " ('iran deal', 12),\n",
       " ('nuclear deal', 12),\n",
       " ('new hampshire', 12),\n",
       " ('fox news', 12),\n",
       " ('islamic state', 12),\n",
       " ('trump clinton', 11),\n",
       " ('trade deal', 11),\n",
       " ('foreign policy', 11),\n",
       " ('new york', 10),\n",
       " ('ted cruz', 10),\n",
       " ('presidential debate', 10),\n",
       " ('jeb bush', 9),\n",
       " ('climate change', 9),\n",
       " ('iran nuclear', 8)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show 20 most common words form ngrams for real news\n",
    "df_train[(df_train.label == 'REAL')][['title_grams']].apply(count_words)['title_grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Seems that both Hillary Clinton and Donald Trump are top represented in both real and fake news. However, Trump more so in real news and Clinton in fake news. \n",
    "\n",
    "*Noteworthy words for fake news:*\n",
    "- onion (probably ref to satire news)\n",
    "- finest \n",
    "- email (clinton scandal)\n",
    "\n",
    "*Noteworthy words for real news:*\n",
    "- deal (iran nuclear deal)\n",
    "- gop\n",
    "- islamic state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3999                                                                                                                 \n",
       "unique    3839                                                                                                                 \n",
       "top       Killing Obama administration rules, dismantling Obamacare and pushing through tax reform are on the early to-do list.\n",
       "freq      41                                                                                                                   \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# general overview -> 41 news articles are identicle, only 4 duplicate titels. \n",
    "# same news article reused and published with new titles\n",
    "# perhaps could we\n",
    "df_train.text.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize text\n",
    "Lets try to structure the text and remove all unuseful elements to conduct a better analysis. Such as:\n",
    "- Remove all but letters\n",
    "- Tokenize words\n",
    "- Convert to lowercase\n",
    "- Filter stopwords\n",
    "- Stem words with lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature -> apply function on text\n",
    "df_train['text_normalized'] = df_train.text.apply(normalizer)\n",
    "\n",
    "# view reuslts\n",
    "# df_train[['text','text_normalized', 'label']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngrams\n",
    "As words mostly matter in context we'll look at bi, tri, quad-grams instead of just individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature -> apply function on normalized_text\n",
    "df_train['text_grams'] = df_train.text_normalized.apply(ngrams)\n",
    "\n",
    "# view reuslts\n",
    "# df_train[['text_grams']].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency count - Fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hillary clinton', 1475),\n",
       " ('donald trump', 1142),\n",
       " ('united state', 836),\n",
       " ('new york', 437),\n",
       " ('white house', 426),\n",
       " ('clinton campaign', 331),\n",
       " ('year old', 277),\n",
       " ('bill clinton', 256),\n",
       " ('presidential election', 246),\n",
       " ('clinton foundation', 237),\n",
       " ('american people', 236),\n",
       " ('secretary state', 235),\n",
       " ('wall street', 231),\n",
       " ('year ago', 195),\n",
       " ('foreign policy', 190),\n",
       " ('democratic party', 180),\n",
       " ('law enforcement', 179),\n",
       " ('look like', 176),\n",
       " ('human right', 175),\n",
       " ('election day', 169)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show 20 most common words form ngrams for fake news\n",
    "df_train[(df_train.label == 'FAKE')][['text_grams']].apply(count_words)['text_grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency count - Real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donald trump', 1177),\n",
       " ('hillary clinton', 1112),\n",
       " ('united state', 1050),\n",
       " ('white house', 1023),\n",
       " ('new york', 976),\n",
       " ('fox news', 647),\n",
       " ('new hampshire', 630),\n",
       " ('islamic state', 521),\n",
       " ('president obama', 518),\n",
       " ('trump said', 496),\n",
       " ('secretary state', 466),\n",
       " ('supreme court', 460),\n",
       " ('ted cruz', 424),\n",
       " ('last week', 423),\n",
       " ('bernie sander', 415),\n",
       " ('foreign policy', 404),\n",
       " ('presidential candidate', 392),\n",
       " ('republican party', 390),\n",
       " ('barack obama', 388),\n",
       " ('south carolina', 350)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show 20 most common words form ngrams for real news\n",
    "df_train[(df_train.label == 'REAL')][['text_grams']].apply(count_words)['text_grams'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "Following the same break down as for titles but for our article text, we find the same results as for titles. \n",
    "\n",
    "*Noteworthy words for fake news:*\n",
    "- wall street\n",
    "- bill clinton\n",
    "- year old\n",
    "\n",
    "*Noteworthy words for real news:*\n",
    "- fox news\n",
    "- president obama\n",
    "- new hampshire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclaimation couting\n",
    "We want to inspect whether fake news use more exclaimation marks compared to real news. Thus we will create a new feature that contains the number of exclaimations marks used in each article in relation to the length of the article. We will assess this function for the main text body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ex_rel_count'] = df_train.text.apply(exclaimation_counter)\n",
    "df_train['ex_rel_count'] = pd.qcut(df_train['ex_rel_count'], 20, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ex_rel_count</th>\n",
       "      <th>(-0.001, 8.81e-05]</th>\n",
       "      <th>(8.81e-05, 0.000227]</th>\n",
       "      <th>(0.000227, 0.000464]</th>\n",
       "      <th>(0.000464, 0.000959]</th>\n",
       "      <th>(0.000959, 0.0361]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAKE</th>\n",
       "      <td>1430</td>\n",
       "      <td>85</td>\n",
       "      <td>132</td>\n",
       "      <td>159</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REAL</th>\n",
       "      <td>1769</td>\n",
       "      <td>115</td>\n",
       "      <td>68</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ex_rel_count  (-0.001, 8.81e-05]  (8.81e-05, 0.000227]  (0.000227, 0.000464]  \\\n",
       "label                                                                          \n",
       "FAKE          1430                85                    132                    \n",
       "REAL          1769                115                   68                     \n",
       "\n",
       "ex_rel_count  (0.000464, 0.000959]  (0.000959, 0.0361]  \n",
       "label                                                   \n",
       "FAKE          159                   185                 \n",
       "REAL          41                    15                  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['label', 'ex_rel_count']).ex_rel_count.count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "Before we get into complex modelling lets try to establish a baseline for the our different models. We will only assume a simple count vectorizer. \n",
    "    - SVM\n",
    "    - NavieBayes - Multinominal\n",
    "    - MaxEntropy (not working atm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0   \n",
       "text                0   \n",
       "label               0   \n",
       "X1                  3966\n",
       "X2                  3997\n",
       "title_normalized    0   \n",
       "title_grams         0   \n",
       "text_normalized     0   \n",
       "text_grams          0   \n",
       "ex_rel_count        0   \n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_train.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label\n",
    "label = df_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer without text modifications\n",
    "count_vectorizer = CountVectorizer(lowercase=False)\n",
    "\n",
    "# apply vector on text in df_train\n",
    "vectorized_data = count_vectorizer.fit_transform(df_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data and labels into train and validation 80/20\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(vectorized_data, label,\n",
    "                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.94      0.84      0.89       383\n",
      "       REAL       0.87      0.95      0.91       417\n",
      "\n",
      "avg / total       0.90      0.90      0.90       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define svm classifer\n",
    "clf_svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3,\n",
    "                        n_iter=5, random_state=42)\n",
    "\n",
    "# fit model \n",
    "clf_svm_output = clf_svm.fit(x_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf_svm_pred = clf_svm_output.predict(x_validation)\n",
    "\n",
    "# model evaluation\n",
    "print(metrics.classification_report(y_validation, clf_svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Naive Bayes - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       FAKE       0.91      0.86      0.89       383\n",
      "       REAL       0.88      0.92      0.90       417\n",
      "\n",
      "avg / total       0.89      0.89      0.89       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define nb classifier\n",
    "clf_nb = MultinomialNB()\n",
    "\n",
    "# fit model \n",
    "clf_nb_output = clf_nb.fit(x_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf_nb_pred = clf_nb_output.predict(x_validation)\n",
    "\n",
    "# mean accuracy\n",
    "print(metrics.classification_report(y_validation, clf_nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxEntropy \n",
    "Not working atm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define nb classifier\n",
    "#clf_maxent = MaxentClassifier(encoding=x_train, weights=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define SVM classifer\n",
    "maxent_clf = GaussianNB()\n",
    "\n",
    "# define multinomial naivebayes classifer\n",
    "multi_nb_clf = MultinomialNB()\n",
    "\n",
    "# define guassian naivebayes classifer\n",
    "gus_nb_clf = GaussianNB()\n",
    "\n",
    "# define max entropy classifer -> doesn't seem to be able to be predefined. we will employ later\n",
    "# maxent_clf = MaxentClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
